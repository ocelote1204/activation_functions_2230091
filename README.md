Activation Functions Visualization

This repository contains a Python implementation to visualize common activation functions used in neural networks, along with their derivatives.

ğŸ“Œ Project Content

src/main.py: Main script that generates plots of activation functions.
requirements.txt: List of dependencies required to run the project.
.gitignore: Files and folders ignored by Git.
README.md: Project documentation.
ğŸ“Š Implemented Activation Functions

ReLU (Rectified Linear Unit) and its derivative.
Sigmoid and its derivative.
Tanh (Hyperbolic Tangent) and its derivative.
Leaky ReLU and its derivative.
ELU (Exponential Linear Unit) and its derivative.
ğŸš€ Installation and Usage

1ï¸ Clone the repository:

ğŸš€ Installation and Usage

1ï¸ Clone the repository:

 git clone https://github.com/ocelote1204/activation_functions_2230091.git
 cd activation_functions_2230091

2ï¸ Create and activate a virtual environment:

 python -m venv venv

On Windows:

venv\Scripts\activate

On macOS/Linux:

source venv/bin/activate

3ï¸ Install dependencies:

 pip install -r requirements.txt

4ï¸ Run the script:

 python src/main.py


ğŸ“Œ Repository Structure

activation_functions_2230091/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ main.py       # Main code for plotting activation functions
â”‚   â”œâ”€â”€ requirements.txt  # Project dependencies
â”‚   â”œâ”€â”€ README.md    # Documentation

ğŸ› ï¸ Dependencies

Python 3.10+
NumPy 2.2.3
Matplotlib 3.10.0

ğŸ“œ License

You can use, modify, and distribute it freely.

ğŸ’¡ Developed by Osmar Amir Sanchez Gomez
 
